PS D:\CMPM 146\P6\src> python train.py
2025-02-19 23:29:57.116299: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-19 23:29:58.045968: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
* Data preprocessing
train dataset:
Found 5000 files belonging to 3 classes.
Using 4000 files for training.
Using 1000 files for validation.
2025-02-19 23:30:01.252975: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
test dataset:
Found 3838 files belonging to 3 classes.
* Training hyper_model for 50 epochs
C:\Users\marco\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\layers\preprocessing\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ rescaling (Rescaling)                │ (None, 150, 150, 3)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d (Conv2D)                      │ (None, 150, 150, 8)         │             224 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d (MaxPooling2D)         │ (None, 75, 75, 8)           │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_1 (Conv2D)                    │ (None, 75, 75, 16)          │           1,168 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_1 (MaxPooling2D)       │ (None, 37, 37, 16)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_2 (Conv2D)                    │ (None, 37, 37, 32)          │           4,640 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_2 (MaxPooling2D)       │ (None, 18, 18, 32)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_3 (Conv2D)                    │ (None, 18, 18, 64)          │          18,496 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_3 (MaxPooling2D)       │ (None, 9, 9, 64)            │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_4 (Conv2D)                    │ (None, 9, 9, 128)           │          73,856 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_4 (MaxPooling2D)       │ (None, 4, 4, 128)           │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flatten (Flatten)                    │ (None, 2048)                │               0 │
C:\Users\marco\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\layers\preprocessing\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ rescaling (Rescaling)                │ (None, 150, 150, 3)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d (Conv2D)                      │ (None, 150, 150, 8)         │             224 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d (MaxPooling2D)         │ (None, 75, 75, 8)           │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_1 (Conv2D)                    │ (None, 75, 75, 16)          │           1,168 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_1 (MaxPooling2D)       │ (None, 37, 37, 16)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_2 (Conv2D)                    │ (None, 37, 37, 32)          │           4,640 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_2 (MaxPooling2D)       │ (None, 18, 18, 32)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_3 (Conv2D)                    │ (None, 18, 18, 64)          │          18,496 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_3 (MaxPooling2D)       │ (None, 9, 9, 64)            │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_4 (Conv2D)                    │ (None, 9, 9, 128)           │          73,856 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_4 (MaxPooling2D)       │ (None, 4, 4, 128)           │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flatten (Flatten)                    │ (None, 2048)                │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense (Dense)                        │ (None, 16)                  │          32,784 │
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ rescaling (Rescaling)                │ (None, 150, 150, 3)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d (Conv2D)                      │ (None, 150, 150, 8)         │             224 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d (MaxPooling2D)         │ (None, 75, 75, 8)           │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_1 (Conv2D)                    │ (None, 75, 75, 16)          │           1,168 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_1 (MaxPooling2D)       │ (None, 37, 37, 16)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_2 (Conv2D)                    │ (None, 37, 37, 32)          │           4,640 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_2 (MaxPooling2D)       │ (None, 18, 18, 32)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_3 (Conv2D)                    │ (None, 18, 18, 64)          │          18,496 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_3 (MaxPooling2D)       │ (None, 9, 9, 64)            │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_4 (Conv2D)                    │ (None, 9, 9, 128)           │          73,856 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_4 (MaxPooling2D)       │ (None, 4, 4, 128)           │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flatten (Flatten)                    │ (None, 2048)                │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense (Dense)                        │ (None, 16)                  │          32,784 │
│ conv2d_1 (Conv2D)                    │ (None, 75, 75, 16)          │           1,168 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_1 (MaxPooling2D)       │ (None, 37, 37, 16)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_2 (Conv2D)                    │ (None, 37, 37, 32)          │           4,640 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_2 (MaxPooling2D)       │ (None, 18, 18, 32)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_3 (Conv2D)                    │ (None, 18, 18, 64)          │          18,496 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_3 (MaxPooling2D)       │ (None, 9, 9, 64)            │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_4 (Conv2D)                    │ (None, 9, 9, 128)           │          73,856 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_4 (MaxPooling2D)       │ (None, 4, 4, 128)           │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flatten (Flatten)                    │ (None, 2048)                │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense (Dense)                        │ (None, 16)                  │          32,784 │
│ max_pooling2d_3 (MaxPooling2D)       │ (None, 9, 9, 64)            │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_4 (Conv2D)                    │ (None, 9, 9, 128)           │          73,856 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_4 (MaxPooling2D)       │ (None, 4, 4, 128)           │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flatten (Flatten)                    │ (None, 2048)                │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense (Dense)                        │ (None, 16)                  │          32,784 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_4 (MaxPooling2D)       │ (None, 4, 4, 128)           │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flatten (Flatten)                    │ (None, 2048)                │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense (Dense)                        │ (None, 16)                  │          32,784 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flatten (Flatten)                    │ (None, 2048)                │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense (Dense)                        │ (None, 16)                  │          32,784 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense (Dense)                        │ (None, 16)                  │          32,784 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout (Dropout)                    │ (None, 16)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_1 (Dense)                      │ (None, 3)                   │              51 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout (Dropout)                    │ (None, 16)                  │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_1 (Dense)                      │ (None, 3)                   │              51 │
│ dense_1 (Dense)                      │ (None, 3)                   │              51 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 131,219 (512.57 KB)
 Trainable params: 131,219 (512.57 KB)
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 131,219 (512.57 KB)
 Trainable params: 131,219 (512.57 KB)
 Trainable params: 131,219 (512.57 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 6s 145ms/step - accuracy: 0.3324 - loss: 1.0987 - val_accuracy: 0.3470 - val_loss: 1.0919
Epoch 2/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 4s 138ms/step - accuracy: 0.3613 - loss: 1.0895 - val_accuracy: 0.3510 - val_loss: 1.0842
Epoch 3/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 143ms/step - accuracy: 0.3806 - loss: 1.0840 - val_accuracy: 0.3800 - val_loss: 1.0637
Epoch 4/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 151ms/step - accuracy: 0.3896 - loss: 1.0752 - val_accuracy: 0.4790 - val_loss: 0.9968
Epoch 5/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 146ms/step - accuracy: 0.4499 - loss: 0.9844 - val_accuracy: 0.5090 - val_loss: 0.9497
Epoch 6/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 146ms/step - accuracy: 0.4836 - loss: 0.9584 - val_accuracy: 0.5910 - val_loss: 0.9010
Epoch 7/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.5322 - loss: 0.9284 - val_accuracy: 0.5910 - val_loss: 0.8839
Epoch 8/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 143ms/step - accuracy: 0.5551 - loss: 0.9166 - val_accuracy: 0.5590 - val_loss: 0.8669
Epoch 9/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.5433 - loss: 0.9048 - val_accuracy: 0.6630 - val_loss: 0.8578
Epoch 10/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 145ms/step - accuracy: 0.5593 - loss: 0.8843 - val_accuracy: 0.6830 - val_loss: 0.8288
Epoch 11/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 148ms/step - accuracy: 0.5575 - loss: 0.8878 - val_accuracy: 0.6800 - val_loss: 0.8131
Epoch 12/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 156ms/step - accuracy: 0.5578 - loss: 0.8579 - val_accuracy: 0.7120 - val_loss: 0.7948
Epoch 13/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 148ms/step - accuracy: 0.5898 - loss: 0.8270 - val_accuracy: 0.6750 - val_loss: 0.7958
Epoch 14/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 144ms/step - accuracy: 0.5793 - loss: 0.8409 - val_accuracy: 0.7020 - val_loss: 0.7624
Epoch 15/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 155ms/step - accuracy: 0.5906 - loss: 0.8067 - val_accuracy: 0.7370 - val_loss: 0.7394
Epoch 16/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.6125 - loss: 0.7857 - val_accuracy: 0.7480 - val_loss: 0.7273
Epoch 17/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 153ms/step - accuracy: 0.6120 - loss: 0.7708 - val_accuracy: 0.7030 - val_loss: 0.7262
Epoch 18/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6310 - loss: 0.7433 - val_accuracy: 0.7090 - val_loss: 0.7061
Epoch 19/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 148ms/step - accuracy: 0.5898 - loss: 0.8270 - val_accuracy: 0.6750 - val_loss: 0.7958
Epoch 14/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 144ms/step - accuracy: 0.5793 - loss: 0.8409 - val_accuracy: 0.7020 - val_loss: 0.7624
Epoch 15/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 155ms/step - accuracy: 0.5906 - loss: 0.8067 - val_accuracy: 0.7370 - val_loss: 0.7394
Epoch 16/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.6125 - loss: 0.7857 - val_accuracy: 0.7480 - val_loss: 0.7273
Epoch 17/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 153ms/step - accuracy: 0.6120 - loss: 0.7708 - val_accuracy: 0.7030 - val_loss: 0.7262
Epoch 18/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6310 - loss: 0.7433 - val_accuracy: 0.7090 - val_loss: 0.7061
Epoch 19/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6094 - loss: 0.7658 - val_accuracy: 0.7530 - val_loss: 0.6840
Epoch 20/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 145ms/step - accuracy: 0.6409 - loss: 0.7175 - val_accuracy: 0.7580 - val_loss: 0.6523
Epoch 21/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.6500 - loss: 0.6911 - val_accuracy: 0.7470 - val_loss: 0.6532
Epoch 22/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.6824 - loss: 0.6746 - val_accuracy: 0.7270 - val_loss: 0.6729
Epoch 23/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6754 - loss: 0.6689 - val_accuracy: 0.7320 - val_loss: 0.6543
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 148ms/step - accuracy: 0.5898 - loss: 0.8270 - val_accuracy: 0.6750 - val_loss: 0.7958
Epoch 14/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 144ms/step - accuracy: 0.5793 - loss: 0.8409 - val_accuracy: 0.7020 - val_loss: 0.7624
Epoch 15/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 155ms/step - accuracy: 0.5906 - loss: 0.8067 - val_accuracy: 0.7370 - val_loss: 0.7394
Epoch 16/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.6125 - loss: 0.7857 - val_accuracy: 0.7480 - val_loss: 0.7273
Epoch 17/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 153ms/step - accuracy: 0.6120 - loss: 0.7708 - val_accuracy: 0.7030 - val_loss: 0.7262
Epoch 18/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6310 - loss: 0.7433 - val_accuracy: 0.7090 - val_loss: 0.7061
Epoch 19/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6094 - loss: 0.7658 - val_accuracy: 0.7530 - val_loss: 0.6840
Epoch 20/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 145ms/step - accuracy: 0.6409 - loss: 0.7175 - val_accuracy: 0.7580 - val_loss: 0.6523
Epoch 21/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.6500 - loss: 0.6911 - val_accuracy: 0.7470 - val_loss: 0.6532
Epoch 22/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.6824 - loss: 0.6746 - val_accuracy: 0.7270 - val_loss: 0.6729
Epoch 23/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 148ms/step - accuracy: 0.5898 - loss: 0.8270 - val_accuracy: 0.6750 - val_loss: 0.7958
Epoch 14/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 144ms/step - accuracy: 0.5793 - loss: 0.8409 - val_accuracy: 0.7020 - val_loss: 0.7624
Epoch 15/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 155ms/step - accuracy: 0.5906 - loss: 0.8067 - val_accuracy: 0.7370 - val_loss: 0.7394
Epoch 16/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.6125 - loss: 0.7857 - val_accuracy: 0.7480 - val_loss: 0.7273
Epoch 17/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 153ms/step - accuracy: 0.6120 - loss: 0.7708 - val_accuracy: 0.7030 - val_loss: 0.7262
Epoch 18/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6310 - loss: 0.7433 - val_accuracy: 0.7090 - val_loss: 0.7061
Epoch 19/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6094 - loss: 0.7658 - val_accuracy: 0.7530 - val_loss: 0.6840
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 144ms/step - accuracy: 0.5793 - loss: 0.8409 - val_accuracy: 0.7020 - val_loss: 0.7624
Epoch 15/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 155ms/step - accuracy: 0.5906 - loss: 0.8067 - val_accuracy: 0.7370 - val_loss: 0.7394
Epoch 16/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.6125 - loss: 0.7857 - val_accuracy: 0.7480 - val_loss: 0.7273
Epoch 17/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 153ms/step - accuracy: 0.6120 - loss: 0.7708 - val_accuracy: 0.7030 - val_loss: 0.7262
Epoch 18/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6310 - loss: 0.7433 - val_accuracy: 0.7090 - val_loss: 0.7061
Epoch 19/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.6125 - loss: 0.7857 - val_accuracy: 0.7480 - val_loss: 0.7273
Epoch 17/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 153ms/step - accuracy: 0.6120 - loss: 0.7708 - val_accuracy: 0.7030 - val_loss: 0.7262
Epoch 18/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6310 - loss: 0.7433 - val_accuracy: 0.7090 - val_loss: 0.7061
Epoch 19/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6310 - loss: 0.7433 - val_accuracy: 0.7090 - val_loss: 0.7061
Epoch 19/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6094 - loss: 0.7658 - val_accuracy: 0.7530 - val_loss: 0.6840
Epoch 20/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 145ms/step - accuracy: 0.6409 - loss: 0.7175 - val_accuracy: 0.7580 - val_loss: 0.6523
Epoch 21/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.6500 - loss: 0.6911 - val_accuracy: 0.7470 - val_loss: 0.6532
Epoch 22/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.6824 - loss: 0.6746 - val_accuracy: 0.7270 - val_loss: 0.6729
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6094 - loss: 0.7658 - val_accuracy: 0.7530 - val_loss: 0.6840
Epoch 20/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 145ms/step - accuracy: 0.6409 - loss: 0.7175 - val_accuracy: 0.7580 - val_loss: 0.6523
Epoch 21/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.6500 - loss: 0.6911 - val_accuracy: 0.7470 - val_loss: 0.6532
Epoch 22/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.6824 - loss: 0.6746 - val_accuracy: 0.7270 - val_loss: 0.6729
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.6500 - loss: 0.6911 - val_accuracy: 0.7470 - val_loss: 0.6532
Epoch 22/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.6824 - loss: 0.6746 - val_accuracy: 0.7270 - val_loss: 0.6729
Epoch 23/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6754 - loss: 0.6689 - val_accuracy: 0.7320 - val_loss: 0.6543
Epoch 24/50
Epoch 23/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6754 - loss: 0.6689 - val_accuracy: 0.7320 - val_loss: 0.6543
Epoch 24/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6754 - loss: 0.6689 - val_accuracy: 0.7320 - val_loss: 0.6543
Epoch 24/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6835 - loss: 0.6527 - val_accuracy: 0.7460 - val_loss: 0.6470
Epoch 25/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 146ms/step - accuracy: 0.6966 - loss: 0.6568 - val_accuracy: 0.7600 - val_loss: 0.6176
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6835 - loss: 0.6527 - val_accuracy: 0.7460 - val_loss: 0.6470
Epoch 25/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 146ms/step - accuracy: 0.6966 - loss: 0.6568 - val_accuracy: 0.7600 - val_loss: 0.6176
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 146ms/step - accuracy: 0.6966 - loss: 0.6568 - val_accuracy: 0.7600 - val_loss: 0.6176
Epoch 26/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 145ms/step - accuracy: 0.6889 - loss: 0.6481 - val_accuracy: 0.7540 - val_loss: 0.6247
Epoch 27/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 145ms/step - accuracy: 0.7049 - loss: 0.6212 - val_accuracy: 0.7520 - val_loss: 0.6283
Epoch 28/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 142ms/step - accuracy: 0.6878 - loss: 0.6334 - val_accuracy: 0.7480 - val_loss: 0.6307
Epoch 29/50
Epoch 30/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 153ms/step - accuracy: 0.7104 - loss: 0.5961 - val_accuracy: 0.7490 - val_loss: 0.6280
Epoch 31/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 150ms/step - accuracy: 0.7225 - loss: 0.5529 - val_accuracy: 0.7540 - val_loss: 0.6209
Epoch 32/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 148ms/step - accuracy: 0.7154 - loss: 0.5785 - val_accuracy: 0.7650 - val_loss: 0.6308
Epoch 33/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 162ms/step - accuracy: 0.7259 - loss: 0.5424 - val_accuracy: 0.7370 - val_loss: 0.6567
Epoch 34/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7282 - loss: 0.5536 - val_accuracy: 0.7530 - val_loss: 0.6251
Epoch 35/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 145ms/step - accuracy: 0.7243 - loss: 0.5482 - val_accuracy: 0.7460 - val_loss: 0.6615
Epoch 36/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 150ms/step - accuracy: 0.7271 - loss: 0.5241 - val_accuracy: 0.7500 - val_loss: 0.6376
Epoch 37/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 139ms/step - accuracy: 0.7387 - loss: 0.4961 - val_accuracy: 0.7520 - val_loss: 0.6819
Epoch 38/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 139ms/step - accuracy: 0.7309 - loss: 0.5143 - val_accuracy: 0.7610 - val_loss: 0.6675
Epoch 39/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 148ms/step - accuracy: 0.7547 - loss: 0.4671 - val_accuracy: 0.7200 - val_loss: 0.7509
Epoch 40/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 147ms/step - accuracy: 0.7394 - loss: 0.5071 - val_accuracy: 0.7390 - val_loss: 0.6979
Epoch 41/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7603 - loss: 0.4494 - val_accuracy: 0.7350 - val_loss: 0.7396
Epoch 42/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 4s 139ms/step - accuracy: 0.7522 - loss: 0.4728 - val_accuracy: 0.7290 - val_loss: 0.7703
Epoch 43/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7456 - loss: 0.4679 - val_accuracy: 0.7420 - val_loss: 0.7337
Epoch 34/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7282 - loss: 0.5536 - val_accuracy: 0.7530 - val_loss: 0.6251
Epoch 35/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 145ms/step - accuracy: 0.7243 - loss: 0.5482 - val_accuracy: 0.7460 - val_loss: 0.6615
Epoch 36/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 150ms/step - accuracy: 0.7271 - loss: 0.5241 - val_accuracy: 0.7500 - val_loss: 0.6376
Epoch 37/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 139ms/step - accuracy: 0.7387 - loss: 0.4961 - val_accuracy: 0.7520 - val_loss: 0.6819
Epoch 38/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 139ms/step - accuracy: 0.7309 - loss: 0.5143 - val_accuracy: 0.7610 - val_loss: 0.6675
Epoch 39/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 148ms/step - accuracy: 0.7547 - loss: 0.4671 - val_accuracy: 0.7200 - val_loss: 0.7509
Epoch 40/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 147ms/step - accuracy: 0.7394 - loss: 0.5071 - val_accuracy: 0.7390 - val_loss: 0.6979
Epoch 41/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7603 - loss: 0.4494 - val_accuracy: 0.7350 - val_loss: 0.7396
Epoch 42/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 4s 139ms/step - accuracy: 0.7522 - loss: 0.4728 - val_accuracy: 0.7290 - val_loss: 0.7703
Epoch 43/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7456 - loss: 0.4679 - val_accuracy: 0.7420 - val_loss: 0.7337
Epoch 44/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 139ms/step - accuracy: 0.7559 - loss: 0.4630 - val_accuracy: 0.7570 - val_loss: 0.7052
Epoch 45/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7282 - loss: 0.5536 - val_accuracy: 0.7530 - val_loss: 0.6251
Epoch 35/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 145ms/step - accuracy: 0.7243 - loss: 0.5482 - val_accuracy: 0.7460 - val_loss: 0.6615
Epoch 36/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 150ms/step - accuracy: 0.7271 - loss: 0.5241 - val_accuracy: 0.7500 - val_loss: 0.6376
Epoch 37/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 139ms/step - accuracy: 0.7387 - loss: 0.4961 - val_accuracy: 0.7520 - val_loss: 0.6819
Epoch 38/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 139ms/step - accuracy: 0.7309 - loss: 0.5143 - val_accuracy: 0.7610 - val_loss: 0.6675
Epoch 39/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 148ms/step - accuracy: 0.7547 - loss: 0.4671 - val_accuracy: 0.7200 - val_loss: 0.7509
Epoch 40/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 147ms/step - accuracy: 0.7394 - loss: 0.5071 - val_accuracy: 0.7390 - val_loss: 0.6979
Epoch 41/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7603 - loss: 0.4494 - val_accuracy: 0.7350 - val_loss: 0.7396
Epoch 42/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 4s 139ms/step - accuracy: 0.7522 - loss: 0.4728 - val_accuracy: 0.7290 - val_loss: 0.7703
Epoch 43/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7456 - loss: 0.4679 - val_accuracy: 0.7420 - val_loss: 0.7337
Epoch 37/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 139ms/step - accuracy: 0.7387 - loss: 0.4961 - val_accuracy: 0.7520 - val_loss: 0.6819
Epoch 38/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 139ms/step - accuracy: 0.7309 - loss: 0.5143 - val_accuracy: 0.7610 - val_loss: 0.6675
Epoch 39/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 148ms/step - accuracy: 0.7547 - loss: 0.4671 - val_accuracy: 0.7200 - val_loss: 0.7509
Epoch 40/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 147ms/step - accuracy: 0.7394 - loss: 0.5071 - val_accuracy: 0.7390 - val_loss: 0.6979
Epoch 41/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7603 - loss: 0.4494 - val_accuracy: 0.7350 - val_loss: 0.7396
Epoch 42/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 4s 139ms/step - accuracy: 0.7522 - loss: 0.4728 - val_accuracy: 0.7290 - val_loss: 0.7703
Epoch 43/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7456 - loss: 0.4679 - val_accuracy: 0.7420 - val_loss: 0.7337
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 139ms/step - accuracy: 0.7309 - loss: 0.5143 - val_accuracy: 0.7610 - val_loss: 0.6675
Epoch 39/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 148ms/step - accuracy: 0.7547 - loss: 0.4671 - val_accuracy: 0.7200 - val_loss: 0.7509
Epoch 40/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 147ms/step - accuracy: 0.7394 - loss: 0.5071 - val_accuracy: 0.7390 - val_loss: 0.6979
Epoch 41/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7603 - loss: 0.4494 - val_accuracy: 0.7350 - val_loss: 0.7396
Epoch 42/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 4s 139ms/step - accuracy: 0.7522 - loss: 0.4728 - val_accuracy: 0.7290 - val_loss: 0.7703
Epoch 43/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7456 - loss: 0.4679 - val_accuracy: 0.7420 - val_loss: 0.7337
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 148ms/step - accuracy: 0.7547 - loss: 0.4671 - val_accuracy: 0.7200 - val_loss: 0.7509
Epoch 40/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 147ms/step - accuracy: 0.7394 - loss: 0.5071 - val_accuracy: 0.7390 - val_loss: 0.6979
Epoch 41/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7603 - loss: 0.4494 - val_accuracy: 0.7350 - val_loss: 0.7396
Epoch 42/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 4s 139ms/step - accuracy: 0.7522 - loss: 0.4728 - val_accuracy: 0.7290 - val_loss: 0.7703
Epoch 43/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7456 - loss: 0.4679 - val_accuracy: 0.7420 - val_loss: 0.7337
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 147ms/step - accuracy: 0.7394 - loss: 0.5071 - val_accuracy: 0.7390 - val_loss: 0.6979
Epoch 41/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7603 - loss: 0.4494 - val_accuracy: 0.7350 - val_loss: 0.7396
Epoch 42/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 4s 139ms/step - accuracy: 0.7522 - loss: 0.4728 - val_accuracy: 0.7290 - val_loss: 0.7703
Epoch 43/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7456 - loss: 0.4679 - val_accuracy: 0.7420 - val_loss: 0.7337
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7603 - loss: 0.4494 - val_accuracy: 0.7350 - val_loss: 0.7396
Epoch 42/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 4s 139ms/step - accuracy: 0.7522 - loss: 0.4728 - val_accuracy: 0.7290 - val_loss: 0.7703
Epoch 43/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7456 - loss: 0.4679 - val_accuracy: 0.7420 - val_loss: 0.7337
Epoch 42/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 4s 139ms/step - accuracy: 0.7522 - loss: 0.4728 - val_accuracy: 0.7290 - val_loss: 0.7703
Epoch 43/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7456 - loss: 0.4679 - val_accuracy: 0.7420 - val_loss: 0.7337
32/32 ━━━━━━━━━━━━━━━━━━━━ 4s 139ms/step - accuracy: 0.7522 - loss: 0.4728 - val_accuracy: 0.7290 - val_loss: 0.7703
Epoch 43/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7456 - loss: 0.4679 - val_accuracy: 0.7420 - val_loss: 0.7337
Epoch 43/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7456 - loss: 0.4679 - val_accuracy: 0.7420 - val_loss: 0.7337
Epoch 44/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7456 - loss: 0.4679 - val_accuracy: 0.7420 - val_loss: 0.7337
Epoch 44/50
Epoch 44/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 139ms/step - accuracy: 0.7559 - loss: 0.4630 - val_accuracy: 0.7570 - val_loss: 0.7052
Epoch 45/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 143ms/step - accuracy: 0.7606 - loss: 0.4412 - val_accuracy: 0.7370 - val_loss: 0.7503
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 143ms/step - accuracy: 0.7606 - loss: 0.4412 - val_accuracy: 0.7370 - val_loss: 0.7503
Epoch 46/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 141ms/step - accuracy: 0.7626 - loss: 0.4474 - val_accuracy: 0.7430 - val_loss: 0.8065
Epoch 47/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 151ms/step - accuracy: 0.7568 - loss: 0.4356 - val_accuracy: 0.7500 - val_loss: 0.7639
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 151ms/step - accuracy: 0.7568 - loss: 0.4356 - val_accuracy: 0.7500 - val_loss: 0.7639
Epoch 48/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 151ms/step - accuracy: 0.7568 - loss: 0.4356 - val_accuracy: 0.7500 - val_loss: 0.7639
Epoch 48/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 151ms/step - accuracy: 0.7568 - loss: 0.4356 - val_accuracy: 0.7500 - val_loss: 0.7639
Epoch 48/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 151ms/step - accuracy: 0.7568 - loss: 0.4356 - val_accuracy: 0.7500 - val_loss: 0.7639
Epoch 48/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7684 - loss: 0.4184 - val_accuracy: 0.7420 - val_loss: 0.7820
Epoch 49/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7519 - loss: 0.4309 - val_accuracy: 0.7440 - val_loss: 0.7586
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 151ms/step - accuracy: 0.7568 - loss: 0.4356 - val_accuracy: 0.7500 - val_loss: 0.7639
Epoch 48/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7684 - loss: 0.4184 - val_accuracy: 0.7420 - val_loss: 0.7820
Epoch 49/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7519 - loss: 0.4309 - val_accuracy: 0.7440 - val_loss: 0.7586
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 151ms/step - accuracy: 0.7568 - loss: 0.4356 - val_accuracy: 0.7500 - val_loss: 0.7639
Epoch 48/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7684 - loss: 0.4184 - val_accuracy: 0.7420 - val_loss: 0.7820
Epoch 49/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7519 - loss: 0.4309 - val_accuracy: 0.7440 - val_loss: 0.7586
Epoch 50/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 149ms/step - accuracy: 0.7497 - loss: 0.4530 - val_accuracy: 0.7470 - val_loss: 0.7452
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 151ms/step - accuracy: 0.7568 - loss: 0.4356 - val_accuracy: 0.7500 - val_loss: 0.7639
Epoch 48/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7684 - loss: 0.4184 - val_accuracy: 0.7420 - val_loss: 0.7820
Epoch 49/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7519 - loss: 0.4309 - val_accuracy: 0.7440 - val_loss: 0.7586
Epoch 50/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 149ms/step - accuracy: 0.7497 - loss: 0.4530 - val_accuracy: 0.7470 - val_loss: 0.7452
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 151ms/step - accuracy: 0.7568 - loss: 0.4356 - val_accuracy: 0.7500 - val_loss: 0.7639
Epoch 48/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7684 - loss: 0.4184 - val_accuracy: 0.7420 - val_loss: 0.7820
Epoch 49/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7519 - loss: 0.4309 - val_accuracy: 0.7440 - val_loss: 0.7586
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 151ms/step - accuracy: 0.7568 - loss: 0.4356 - val_accuracy: 0.7500 - val_loss: 0.7639
Epoch 48/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7684 - loss: 0.4184 - val_accuracy: 0.7420 - val_loss: 0.7820
Epoch 49/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7519 - loss: 0.4309 - val_accuracy: 0.7440 - val_loss: 0.7586
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 151ms/step - accuracy: 0.7568 - loss: 0.4356 - val_accuracy: 0.7500 - val_loss: 0.7639
Epoch 48/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7684 - loss: 0.4184 - val_accuracy: 0.7420 - val_loss: 0.7820
Epoch 49/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 151ms/step - accuracy: 0.7568 - loss: 0.4356 - val_accuracy: 0.7500 - val_loss: 0.7639
Epoch 48/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7684 - loss: 0.4184 - val_accuracy: 0.7420 - val_loss: 0.7820
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7684 - loss: 0.4184 - val_accuracy: 0.7420 - val_loss: 0.7820
Epoch 49/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 152ms/step - accuracy: 0.7519 - loss: 0.4309 - val_accuracy: 0.7440 - val_loss: 0.7586
Epoch 50/50
32/32 ━━━━━━━━━━━━━━━━━━━━ 5s 149ms/step - accuracy: 0.7497 - loss: 0.4530 - val_accuracy: 0.7470 - val_loss: 0.7452
* Evaluating hyper_model
30/30 ━━━━━━━━━━━━━━━━━━━━ 5s 167ms/step - accuracy: 0.6777 - loss: 0.7697
* Confusion Matrix for hyper_model
30/30 ━━━━━━━━━━━━━━━━━━━━ 2s 53ms/step
2025-02-19 23:34:06.669488: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
[[1163  355  256]
 [ 132  917  184]
 [  36   99  696]]
30/30 ━━━━━━━━━━━━━━━━━━━━ 5s 167ms/step - accuracy: 0.6777 - loss: 0.7697
* Confusion Matrix for hyper_model
30/30 ━━━━━━━━━━━━━━━━━━━━ 2s 53ms/step
2025-02-19 23:34:06.669488: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
[[1163  355  256]
 [ 132  917  184]
 [  36   99  696]]
* Confusion Matrix for hyper_model
30/30 ━━━━━━━━━━━━━━━━━━━━ 2s 53ms/step
2025-02-19 23:34:06.669488: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
[[1163  355  256]
 [ 132  917  184]
 [  36   99  696]]
[[1163  355  256]
 [ 132  917  184]
 [  36   99  696]]
* Model saved as results/hyper_model_50_epochs_timestamp_1740036846.keras